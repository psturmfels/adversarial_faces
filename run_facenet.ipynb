{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "### import tf and shut up tensorflow deprecation warnings ####\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import numpy as np\n",
    "\n",
    "### import facenet repo ####\n",
    "import sys\n",
    "\n",
    "#### OpenCV and matplotlib imports\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "# useful for finding the xml file CV2 needs for detection\n",
    "import pkg_resources\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "\n",
    "import seaborn\n",
    "\n",
    "IMG_WIDTH = 160\n",
    "IMG_HEIGHT = 160\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "DATASET_BASE = \"/data/vggface/test\"\n",
    "\n",
    "BASE_MODELS_PATH = \"/home/ivan/adversarial_faces/weights-facenet\"\n",
    "MODEL_TO_CHECKPOINT = {\n",
    "    \"20180408-102900\": \"model-20180408-102900.ckpt-90\",\n",
    "    \"20180402-114759\": \"model-20180402-114759.ckpt-275\"\n",
    "}\n",
    "KERAS_MODEL_PATH = \"keras-facenet/model/facenet_keras.h5\"\n",
    "OPENCV_HAAR_PATH = \"opencv-data/haarcascades\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDING_BOXES = {}\n",
    "with open(os.path.join(\"/data/vggface\", \"bb_landmark\", \"loose_bb_test.csv\")) as f:\n",
    "    header = next(f)\n",
    "    for l in f:\n",
    "        l = l.strip(\"\\n\")\n",
    "        name_id, x, y, w, h = l.split(\",\")\n",
    "        name_id = name_id.strip(\"\\\"\") + \".jpg\"\n",
    "        BOUNDING_BOXES[name_id] = (int(x), int(y), int(w), int(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    face_cascade = cv2.CascadeClassifier(OPENCV_HAAR_PATH)\n",
    "    assert not (img is None)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return face_cascade.detectMultiScale(gray)\n",
    "    \n",
    "def crop_resize_to_face(img):\n",
    "    faces = detect_face(img)\n",
    "    # if we have detected faces, pick the first one\n",
    "    if len(faces) > 0:\n",
    "        x, y, w, h = faces[0]\n",
    "        img = img[y : y + h, x : x + w, :]\n",
    "    return cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    \n",
    "def load_test_list(path):\n",
    "    s2f = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for l in f:\n",
    "            l = l.strip(\"\\n\")\n",
    "            subject, file = l.split(\"/\")\n",
    "            if subject in s2f:\n",
    "                s2f[subject].append(l)\n",
    "            else:\n",
    "                s2f[subject] = [l]\n",
    "    return s2f\n",
    "\n",
    "def plot_distances(base_identity_vectors, other_identity_vectors, dist_func=euclidean_distances):\n",
    "    plt.figure()\n",
    "    self_dist = pairwise_self(base_identity_vectors, dist_func=dist_func)\n",
    "    seaborn.distplot(self_dist, label=\"base identity to self\", hist=False)\n",
    "    \n",
    "    for indx, other in enumerate(other_identity_vectors):\n",
    "        random_subset = np.random.choice(len(other), len(base_identity_vectors))\n",
    "        other = np.take(other, random_subset, axis=0)\n",
    "        seaborn.distplot(\n",
    "            np.ravel(dist_func(base_identity_vectors, other)), \n",
    "            hist=False, \n",
    "            label=\"base to different identity\"\n",
    "        )\n",
    "    plt.legend()\n",
    "\n",
    "def get_error_stats_at_threshold(same_identity_distances, different_identity_distances, threshold):\n",
    "    same_identity_distances = np.array(same_identity_distances)\n",
    "    different_identity_distances = np.array(different_identity_distances)\n",
    "    if len(different_identity_distances.shape) > 1:\n",
    "        raise Exception(\"Expeced different identity distances to be of rank 1 but is shape {0}\".format(different_identity_distances.shape))\n",
    "    if len(same_identity_distances.shape) > 1:\n",
    "        raise Exception(\"Expeced same identity distances to be of rank 1 but is shape {0}\".format(same_identity_distances.shape))\n",
    "\n",
    "    tpr = np.count_nonzero(same_identity_distances <= threshold) / float(len(same_identity_distances))\n",
    "    fpr = np.count_nonzero(different_identity_distances <= threshold) / float(len(different_identity_distances))\n",
    "    return tpr, fpr\n",
    "\n",
    "def pairwise_self(vectors, dist_func=euclidean_distances):\n",
    "    arr = dist_func(vectors, vectors)\n",
    "    return arr[np.tril_indices(len(arr))]\n",
    "\n",
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
    "    return y\n",
    "\n",
    "def load_crop_cv2(path):\n",
    "    full_path = os.path.join(DATASET_BASE, path)\n",
    "    img = cv2.imread(full_path)\n",
    "    assert not (img is None), \"Image at full path {} is None\".format(full_path)\n",
    "    return crop_resize_to_face(\n",
    "        cv2.cvtColor(\n",
    "            img, \n",
    "            cv2.COLOR_BGR2RGB\n",
    "        ))\n",
    "\n",
    "def load_crop_pillow_provided_landmarks(path):\n",
    "    x, y, w, h = BOUNDING_BOXES[path]\n",
    "    img = Image.open(os.path.join(DATASET_BASE, path))\n",
    "    assert not (img is None)\n",
    "    img = img.crop((x, y, x + w, y + h))\n",
    "    return np.array(img.resize((IMG_WIDTH, IMG_HEIGHT)))\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Normalizes an embedding to have unit length in the l2 metric.\n",
    "\n",
    "    Args:\n",
    "     x: A batch of numpy embeddings\n",
    "    \"\"\" \n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x),\n",
    "                                        axis=axis,\n",
    "                                        keepdims=True),\n",
    "                                 epsilon))\n",
    "    return output\n",
    "\n",
    "def do_model(\n",
    "    load_preprocess_func,\n",
    "    num_subjects=3,\n",
    "    dist_func=euclidean_distances\n",
    "):\n",
    "    subj2vects = []\n",
    "    model = tf.keras.models.load_model(KERAS_MODEL_PATH)\n",
    "    \n",
    "    for subject in sorted(subj2files.keys())[:3]:\n",
    "        curr_subj_imgs = np.array([load_preprocess_func(x) for x in subj2files[subject]])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(curr_subj_imgs[0])        \n",
    "        curr_subj_vects = l2_normalize(model.predict(curr_subj_imgs))\n",
    "        subj2vects.append(curr_subj_vects)\n",
    "\n",
    "    for indx in range(num_subjects):\n",
    "        other_indices = set(range(num_subjects)) - set([indx])\n",
    "        other_vects = []\n",
    "        for j in other_indices:\n",
    "            other_vects.append(subj2vects[j])\n",
    "        plot_distances(subj2vects[indx], other_vects, dist_func=dist_func)\n",
    "\n",
    "    all_same_identity = []\n",
    "    for x in subj2vects[:1]:\n",
    "        all_same_identity.extend(pairwise_self(x, dist_func=dist_func))\n",
    "\n",
    "    all_different_identity = []\n",
    "    for i in range(len(subj2vects)):\n",
    "        for j in set(range(len(subj2vects))) - set([i]):\n",
    "            all_different_identity.extend(np.ravel(dist_func(subj2vects[i], subj2vects[j])))\n",
    "\n",
    "    roc_curve = np.array([get_error_stats_at_threshold(\n",
    "        all_same_identity,\n",
    "        all_different_identity,\n",
    "        x\n",
    "    ) for x in np.arange(1e-6, 2.0, 0.01)])\n",
    "    plt.figure()\n",
    "    plt.plot(roc_curve[:, 1], roc_curve[:, 0], label=\"roc curve\")\n",
    "    plt.plot(np.arange(0.0, 1.0, 0.05), np.arange(0.0, 1.0, 0.05), label=\"y=x\")\n",
    "    plt.legend()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj2files = load_test_list(os.path.join(\"/data/vggface\", \"test_list.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class 'cv2.CascadeClassifier'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/core/src/persistence_c.cpp:388: error: (-49:Unknown error code -49) Input file is empty in function 'cvOpenFileStorage'\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-08d61d86d696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m do_model(\n\u001b[1;32m      2\u001b[0m     \u001b[0mdist_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcosine_distances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mload_preprocess_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprewhiten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_crop_cv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-7-7e25cc60bbbc>\u001b[0m in \u001b[0;36mdo_model\u001b[0;34m(load_preprocess_func, num_subjects, dist_func)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj2files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mcurr_subj_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_preprocess_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubj2files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7e25cc60bbbc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj2files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mcurr_subj_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_preprocess_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubj2files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-08d61d86d696>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(im)\u001b[0m\n\u001b[1;32m      1\u001b[0m do_model(\n\u001b[1;32m      2\u001b[0m     \u001b[0mdist_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcosine_distances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mload_preprocess_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprewhiten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_crop_cv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-7-7e25cc60bbbc>\u001b[0m in \u001b[0;36mload_crop_cv2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     70\u001b[0m         cv2.cvtColor(\n\u001b[1;32m     71\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         ))\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7e25cc60bbbc>\u001b[0m in \u001b[0;36mcrop_resize_to_face\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcrop_resize_to_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# if we have detected faces, pick the first one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7e25cc60bbbc>\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mface_cascade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPENCV_HAAR_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <class 'cv2.CascadeClassifier'> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "do_model(\n",
    "    dist_func=cosine_distances,\n",
    "    load_preprocess_func=lambda im: prewhiten(load_crop_cv2(im))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_model(\n",
    "     dist_func=cosine_distances, \n",
    "     load_preprocess_func=lambda im: prewhiten(load_crop_pillow_provided_landmarks(im))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.data.haarcascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
