{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import pairwise_distances, roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from inception_resnet_v1 import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    \"\"\"\n",
    "    A helper function to whiten an image, or a batch of images.\n",
    "    Args:\n",
    "        x: An image or batch of images.\n",
    "    \"\"\"\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        print(x.ndim)\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "#     std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std\n",
    "    return y\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Normalizes an embedding to have unit length in the l2 metric.\n",
    "    Args:\n",
    "        x: A batch of numpy embeddings\n",
    "    \"\"\"\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x),\n",
    "                                           axis=axis,\n",
    "                                           keepdims=True),\n",
    "                                    epsilon))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonImages:\n",
    "    def __init__(self, person_name):\n",
    "        self.clean_folder = \"\"\n",
    "        self.clean_images = []\n",
    "        self.adversarial_images = []\n",
    "        self.reloaded_adversarial_images = []\n",
    "        self.orig_mean = None\n",
    "        self.orig_std = None\n",
    "        self.person_name = person_name\n",
    "        self.adversarial_save_folder = None\n",
    "    \n",
    "    def _load_one_facenet(self, path, resize_size=None, prewhiten_img=True):\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "    \n",
    "            \n",
    "        if resize_size:\n",
    "            img = img.resize((resize_size, resize_size))\n",
    "            \n",
    "        img = (np.array(img)).astype(np.float32)\n",
    "        \n",
    "        if prewhiten_img:\n",
    "            img = prewhiten(img)\n",
    "            \n",
    "        return img\n",
    "        \n",
    "    def _load_folder_for_facenet(self, folder, resize_size=None):\n",
    "        paths_list = glob.glob(os.path.join(folder, \"*\"))\n",
    "        final_imgs = []\n",
    "        for img_path in paths_list:\n",
    "            final_imgs.append(\n",
    "                self._load_one_facenet(\n",
    "                    img_path, prewhiten_img=False, resize_size=resize_size))\n",
    "        \n",
    "        final_imgs = np.array(final_imgs)\n",
    "        mean, std = np.mean(final_imgs), np.std(final_imgs)\n",
    "        final_imgs = prewhiten(np.array(final_imgs))\n",
    "        return final_imgs, mean, std, paths_list\n",
    "        \n",
    "    def load_clean_from_folder(self, clean_folder, resize_size=160):\n",
    "        self.clean_folder = clean_folder\n",
    "        self.clean_images, self.orig_mean, self.orig_std, self.orig_paths = self._load_folder_for_facenet(\n",
    "            clean_folder, resize_size=resize_size)\n",
    "    \n",
    "    def _undo_preprocess(self, images):\n",
    "        restored_images = images.copy()\n",
    "        restored_images  *= self.orig_std\n",
    "        restored_images += self.orig_mean\n",
    "        restored_images = np.clip(restored_images, 0.0, 255.0)\n",
    "        return np.uint8(restored_images)\n",
    "    \n",
    "    def _compute_embeddings(self, model, images):\n",
    "        return model.predict(np.array(images), batch_size=len(images))\n",
    "    \n",
    "    def get_clean_for_display(self):\n",
    "        return self._undo_preprocess(self.clean_images)\n",
    "    \n",
    "    def compute_clean_embeddings_with_model(self, model):\n",
    "        self.clean_embeddings = self._compute_embeddings(model, self.clean_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel:\n",
    "    def __init__(self, model_path, inputs=None, sess=None):\n",
    "        if inputs is None:\n",
    "            self.model_inputs = tf.placeholder(tf.float32, shape=(None, 160, 160, 3))\n",
    "        else:\n",
    "            self.model_inputs = inputs\n",
    "\n",
    "        self.net, self.endpoints = inference(\n",
    "            self.model_inputs, keep_probability=1.0, bottleneck_layer_size=512, phase_train=False)\n",
    "\n",
    "        model_name = dataset_to_model_name[\"vggface2\"]\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        if sess is None:\n",
    "            self.sess = tf.Session()\n",
    "        else:\n",
    "            self.sess = sess\n",
    "            \n",
    "        saver.restore(self.sess, model_path)\n",
    "    \n",
    "    def predict(self, inputs, batch_size):\n",
    "        return self.sess.run(self.net, feed_dict={self.model_inputs: inputs})\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.sess.close()\n",
    "\n",
    "dataset_to_model_name = {\n",
    "    \"casia-webface\": \"20180408-102900\",\n",
    "    \"vggface2\": \"20180402-114759\"\n",
    "}\n",
    "\n",
    "dataset_to_ckpt_number = {\n",
    "    \"casia-webface\": \"90\",\n",
    "    \"vggface2\": \"275\"\n",
    "}\n",
    "\n",
    "def build_model(dataset_name, inputs=None, sess=None):\n",
    "    model_name = dataset_to_model_name[dataset_name]\n",
    "    model = MyModel(\n",
    "        os.path.join(\n",
    "            \"/home/ivan/facenet/models\",\n",
    "            model_name,\n",
    "            \"model-{model_name}.ckpt-{ckpt_num}\".format(\n",
    "                model_name=dataset_to_model_name[dataset_name],\n",
    "                ckpt_num=dataset_to_ckpt_number[dataset_name]\n",
    "            )),\n",
    "        inputs, \n",
    "        sess\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_for_id_clean(identity):\n",
    "    if identity == \"n000958\":\n",
    "        return \"/data/vggface/test_perturbed_sampled/{id}/community_naive_mean/n000029/epsilon_0.0/png\".format(id=identity)\n",
    "    else:\n",
    "        return \"/data/vggface/test_perturbed_sampled/{id}/community_naive_mean/n000958/epsilon_0.0/png\".format(id=identity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_person(person_name, path_for_id_fn, model=None):\n",
    "    person_a = PersonImages(person_name)\n",
    "    person_a.load_clean_from_folder(path_for_id_fn(person_a.person_name))\n",
    "    if model is not None:\n",
    "        print(\"Computing embeddings for\", person_name)\n",
    "        person_a.compute_clean_embeddings_with_model(model)\n",
    "    return person_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from /home/ivan/facenet/models/20180402-114759/model-20180402-114759.ckpt-275\n",
      "Computing embeddings for n001781\n",
      "Computing embeddings for n009232\n",
      "Computing embeddings for n000958\n",
      "Computing embeddings for n003356\n",
      "Computing embeddings for n008655\n",
      "Computing embeddings for n008613\n",
      "Computing embeddings for n004658\n",
      "Computing embeddings for n001683\n",
      "Computing embeddings for n002647\n",
      "Computing embeddings for n009288\n",
      "Computing embeddings for n005427\n",
      "Computing embeddings for n002763\n",
      "Computing embeddings for n002503\n",
      "Computing embeddings for n003215\n",
      "Computing embeddings for n005359\n",
      "Computing embeddings for n005303\n",
      "Computing embeddings for n007548\n",
      "Computing embeddings for n000029\n",
      "Computing embeddings for n009114\n"
     ]
    }
   ],
   "source": [
    "vggface2_model = build_model(\"vggface2\")\n",
    "people = [\n",
    "    build_person(person_name, path_for_id_clean, vggface2_model) \\\n",
    "    for person_name in os.listdir(\"/data/vggface/test_perturbed_sampled\")\n",
    "]\n",
    "del vggface2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vggface_model(inputs, sess):\n",
    "    return build_model(\"vggface2\", inputs, sess)\n",
    "\n",
    "def build_casiawebface_model(inputs, sess):\n",
    "    return build_model(\"casia-webface\", inputs, sess)\n",
    "\n",
    "    \n",
    "def attack_batch(\n",
    "    build_model_fn, \n",
    "    input_images,\n",
    "    target_vectors,\n",
    "    learning_rate,\n",
    "    epsilon,\n",
    "    max_iters\n",
    "):\n",
    "    input_images = np.array(input_images)\n",
    "    batch_size, orig_h, orig_w, orig_c = input_images.shape\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            targets_var = tf.get_variable(\n",
    "                name=\"targets\",\n",
    "                shape=target_vectors.shape,\n",
    "            )\n",
    "            sess.run(tf.assign(targets_var, target_vectors))\n",
    "            \n",
    "            noisy_images_var = tf.get_variable(\n",
    "                name=\"noisy_images\",\n",
    "                shape=input_images.shape\n",
    "            )\n",
    "            sess.run(tf.assign(noisy_images_var, input_images + tf.random.normal(0.0, 0.1)))\n",
    "\n",
    "#             noise_var = tf.get_variable(\n",
    "#                 name=\"adversarial_noise\",\n",
    "#                 shape=input_images.shape,\n",
    "#                 initializer=tf.initializers.truncated_normal(\n",
    "#                     mean=np.mean(input_images),\n",
    "#                     std=np.std(input_images)\n",
    "#                 )\n",
    "#             )\n",
    "            \n",
    "                        \n",
    "            randomized_images_plus_noise = tf.image.random_brightness(\n",
    "                    noisy_images_var, 0.5)\n",
    "\n",
    "            randomized_images_plus_noise = tf.image.random_crop(\n",
    "                randomized_images_plus_noise, \n",
    "                [batch_size, orig_h - 10, orig_w - 10, 3]\n",
    "            )\n",
    "            \n",
    "            randomized_images_plus_noise = tf.image.resize_images(\n",
    "                randomized_images_plus_noise, [orig_h, orig_w])\n",
    "\n",
    "            randomized_images_plus_noise += tf.random.normal(\n",
    "                randomized_images_plus_noise.shape, 0.0, 0.75)\n",
    "            \n",
    "            model = build_model_fn(\n",
    "                inputs=randomized_images_plus_noise, \n",
    "                sess=sess\n",
    "            )\n",
    "            \n",
    "            model_outputs = tf.nn.l2_normalize(model.net, axis=0)\n",
    "            targets = tf.nn.l2_normalize(targets_var, axis=0)\n",
    "            loss = tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "            \n",
    "            for i in range(max_iters):\n",
    "                grads = tf.gradients(loss, [noisy_images_var])[0]\n",
    "                sess.run([\n",
    "                    tf.assign(\n",
    "                        noisy_images_var,\n",
    "                        noisy_images_var - learning_rate * tf.sign(grads)\n",
    "                    ),\n",
    "                    tf.assign(\n",
    "                        noise_var, \n",
    "                        tf.clip_by_value(\n",
    "                            noisy_images_var, \n",
    "                            input_images - epsilon,\n",
    "                            input_images + epsilon\n",
    "                        ))\n",
    "                ])\n",
    "            return sess.run(noisy_images_var)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
