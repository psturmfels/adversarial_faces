{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import pairwise_distances, roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from inception_resnet_v1 import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    \"\"\"\n",
    "    A helper function to whiten an image, or a batch of images.\n",
    "    Args:\n",
    "        x: An image or batch of images.\n",
    "    \"\"\"\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        print(x.ndim)\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "#     std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std\n",
    "    return y\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Normalizes an embedding to have unit length in the l2 metric.\n",
    "    Args:\n",
    "        x: A batch of numpy embeddings\n",
    "    \"\"\"\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x),\n",
    "                                           axis=axis,\n",
    "                                           keepdims=True),\n",
    "                                    epsilon))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonImages:\n",
    "    def __init__(self, person_name):\n",
    "        self.clean_folder = \"\"\n",
    "        self.clean_images = []\n",
    "        self.adversarial_images = []\n",
    "        self.orig_mean = None\n",
    "        self.orig_std = None\n",
    "        self.orig_paths = []\n",
    "        self.person_name = person_name\n",
    "    \n",
    "    def _load_one_facenet(self, path, resize_size=None, prewhiten_img=True):\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "    \n",
    "            \n",
    "        if resize_size:\n",
    "            img = img.resize((resize_size, resize_size))\n",
    "            \n",
    "        img = (np.array(img)).astype(np.float32)\n",
    "        \n",
    "        if prewhiten_img:\n",
    "            img = prewhiten(img)\n",
    "            \n",
    "        return img\n",
    "        \n",
    "    def _load_folder_for_facenet(self, folder, resize_size=None):\n",
    "        paths_list = glob.glob(os.path.join(folder, \"*\"))\n",
    "        final_imgs = []\n",
    "        for img_path in paths_list:\n",
    "            final_imgs.append(\n",
    "                self._load_one_facenet(\n",
    "                    img_path, prewhiten_img=False, resize_size=resize_size))\n",
    "        \n",
    "        final_imgs = np.array(final_imgs)\n",
    "        mean, std = np.mean(final_imgs), np.std(final_imgs)\n",
    "        final_imgs = prewhiten(np.array(final_imgs))\n",
    "        return final_imgs, mean, std, paths_list\n",
    "        \n",
    "    def load_clean_from_folder(self, clean_folder, resize_size=160):\n",
    "        self.clean_folder = clean_folder\n",
    "        self.clean_images, self.orig_mean, self.orig_std, self.orig_paths = self._load_folder_for_facenet(\n",
    "            clean_folder, resize_size=resize_size)\n",
    "    \n",
    "    def _undo_preprocess(self, images):\n",
    "        restored_images = images.copy()\n",
    "        restored_images  *= self.orig_std\n",
    "        restored_images += self.orig_mean\n",
    "        restored_images = np.clip(restored_images, 0.0, 255.0)\n",
    "        return np.uint8(restored_images)\n",
    "    \n",
    "    def _compute_embeddings(self, model, images):\n",
    "        return model.predict(np.array(images), batch_size=len(images))\n",
    "    \n",
    "    def get_clean_for_display(self):\n",
    "        return self._undo_preprocess(self.clean_images)\n",
    "    \n",
    "    def compute_clean_embeddings_with_model(self, model):\n",
    "        self.clean_embeddings = self._compute_embeddings(model, self.clean_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel:\n",
    "    def __init__(self, model_path, inputs=None, sess=None):\n",
    "        if inputs is None:\n",
    "            self.model_inputs = tf.placeholder(tf.float32, shape=(None, 160, 160, 3))\n",
    "        else:\n",
    "            self.model_inputs = inputs\n",
    "        \n",
    "        vars_before = tf.global_variables()\n",
    "        self.net, self.endpoints = inference(\n",
    "            self.model_inputs, keep_probability=1.0, bottleneck_layer_size=512, phase_train=False)\n",
    "        vars_after = tf.global_variables()\n",
    "        \n",
    "        model_name = dataset_to_model_name[\"vggface2\"]\n",
    "        saver = tf.train.Saver(list(set(vars_after) - set(vars_before)))\n",
    "        \n",
    "        if sess is None:\n",
    "            self.sess = tf.Session()\n",
    "        else:\n",
    "            self.sess = sess\n",
    "            \n",
    "        saver.restore(self.sess, model_path)\n",
    "    \n",
    "    def predict(self, inputs, batch_size):\n",
    "        return self.sess.run(self.net, feed_dict={self.model_inputs: inputs})\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.sess.close()\n",
    "\n",
    "dataset_to_model_name = {\n",
    "    \"casia-webface\": \"20180408-102900\",\n",
    "    \"vggface2\": \"20180402-114759\"\n",
    "}\n",
    "\n",
    "dataset_to_ckpt_number = {\n",
    "    \"casia-webface\": \"90\",\n",
    "    \"vggface2\": \"275\"\n",
    "}\n",
    "\n",
    "def build_model(dataset_name, inputs=None, sess=None):\n",
    "    model_name = dataset_to_model_name[dataset_name]\n",
    "    model = MyModel(\n",
    "        os.path.join(\n",
    "            \"/home/ivan/facenet/models\",\n",
    "            model_name,\n",
    "            \"model-{model_name}.ckpt-{ckpt_num}\".format(\n",
    "                model_name=dataset_to_model_name[dataset_name],\n",
    "                ckpt_num=dataset_to_ckpt_number[dataset_name]\n",
    "            )),\n",
    "        inputs, \n",
    "        sess\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_for_id_clean(identity):\n",
    "    if identity == \"n000958\":\n",
    "        return \"/data/vggface/test_perturbed_sampled/{id}/community_naive_mean/n000029/epsilon_0.0/png\".format(id=identity)\n",
    "    else:\n",
    "        return \"/data/vggface/test_perturbed_sampled/{id}/community_naive_mean/n000958/epsilon_0.0/png\".format(id=identity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_person(person_name, path_for_id_fn, model=None):\n",
    "    person_a = PersonImages(person_name)\n",
    "    person_a.load_clean_from_folder(path_for_id_fn(person_a.person_name))\n",
    "    if model is not None:\n",
    "        print(\"Computing embeddings for\", person_name)\n",
    "        person_a.compute_clean_embeddings_with_model(model)\n",
    "    return person_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from /home/ivan/facenet/models/20180402-114759/model-20180402-114759.ckpt-275\n",
      "Computing embeddings for n001781\n",
      "Computing embeddings for n009232\n",
      "Computing embeddings for n000958\n",
      "Computing embeddings for n003356\n",
      "Computing embeddings for n008655\n",
      "Computing embeddings for n008613\n",
      "Computing embeddings for n004658\n",
      "Computing embeddings for n001683\n",
      "Computing embeddings for n002647\n",
      "Computing embeddings for n009288\n",
      "Computing embeddings for n005427\n",
      "Computing embeddings for n002763\n",
      "Computing embeddings for n002503\n",
      "Computing embeddings for n003215\n",
      "Computing embeddings for n005359\n",
      "Computing embeddings for n005303\n",
      "Computing embeddings for n007548\n",
      "Computing embeddings for n000029\n",
      "Computing embeddings for n009114\n"
     ]
    }
   ],
   "source": [
    "vggface2_model = build_model(\"vggface2\")\n",
    "people = [\n",
    "    build_person(person_name, path_for_id_clean, vggface2_model) \\\n",
    "    for person_name in os.listdir(\"/data/vggface/test_perturbed_sampled\")\n",
    "]\n",
    "del vggface2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vggface_model(inputs, sess):\n",
    "    return build_model(\"vggface2\", inputs, sess)\n",
    "\n",
    "def build_casiawebface_model(inputs, sess):\n",
    "    return build_model(\"casia-webface\", inputs, sess)\n",
    "\n",
    "    \n",
    "def attack_batch(\n",
    "    build_model_fn, \n",
    "    input_images,\n",
    "    target_vectors,\n",
    "    learning_rate,\n",
    "    epsilon,\n",
    "    max_iters\n",
    "):\n",
    "    input_images = np.array(input_images)\n",
    "    batch_size, orig_h, orig_w, orig_c = input_images.shape\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            targets_var = tf.get_variable(\n",
    "                name=\"targets\",\n",
    "                shape=target_vectors.shape,\n",
    "            )\n",
    "            sess.run(tf.assign(targets_var, target_vectors))\n",
    "            \n",
    "            noisy_images_var = tf.get_variable(\n",
    "                name=\"noisy_images\",\n",
    "                shape=input_images.shape\n",
    "            )\n",
    "            sess.run(tf.assign(noisy_images_var, input_images + tf.random.normal(input_images.shape, 0.0, 0.1)))\n",
    "\n",
    "#             noise_var = tf.get_variable(\n",
    "#                 name=\"adversarial_noise\",\n",
    "#                 shape=input_images.shape,\n",
    "#                 initializer=tf.initializers.truncated_normal(\n",
    "#                     mean=np.mean(input_images),\n",
    "#                     std=np.std(input_images)\n",
    "#                 )\n",
    "#             )\n",
    "            \n",
    "                        \n",
    "            randomized_images_plus_noise = tf.image.random_brightness(\n",
    "                    noisy_images_var, 0.5)\n",
    "\n",
    "            randomized_images_plus_noise = tf.image.random_crop(\n",
    "                randomized_images_plus_noise, \n",
    "                [batch_size, orig_h - 10, orig_w - 10, 3]\n",
    "            )\n",
    "            \n",
    "            randomized_images_plus_noise = tf.image.resize_images(\n",
    "                randomized_images_plus_noise, [orig_h, orig_w])\n",
    "\n",
    "            randomized_images_plus_noise += tf.random.normal(\n",
    "                randomized_images_plus_noise.shape, 0.0, 0.75)\n",
    "            \n",
    "            model = build_model_fn(\n",
    "                inputs=randomized_images_plus_noise, \n",
    "                sess=sess\n",
    "            )\n",
    "            \n",
    "            model_outputs = tf.nn.l2_normalize(model.net, axis=0)\n",
    "            targets = tf.nn.l2_normalize(targets_var, axis=0)\n",
    "            print(\"model outputs shape\", model_outputs.shape.as_list(), \"targets shape\", targets.shape.as_list())\n",
    "            multiplied = tf.multiply(model_outputs, targets)\n",
    "            print(\"multiplied shape\", multiplied.shape.as_list())\n",
    "            loss = tf.reduce_sum(multiplied)\n",
    "            \n",
    "            losses = []\n",
    "            for i in range(max_iters):\n",
    "                grads = tf.gradients(loss, [noisy_images_var])[0]\n",
    "                assert grads is not None\n",
    "                losses.append(sess.run(loss))\n",
    "                sess.run([\n",
    "                    tf.assign(\n",
    "                        noisy_images_var,\n",
    "                        noisy_images_var - learning_rate * tf.sign(grads)\n",
    "                    ),\n",
    "                    tf.assign(\n",
    "                        noisy_images_var, \n",
    "                        tf.clip_by_value(\n",
    "                            noisy_images_var, \n",
    "                            input_images - epsilon,\n",
    "                            input_images + epsilon\n",
    "                        ))\n",
    "                ])\n",
    "            return sess.run(noisy_images_var), losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_batch_cw(\n",
    "    build_model_fn, \n",
    "    input_images,\n",
    "    target_vectors,\n",
    "    learning_rate,\n",
    "    epsilon,\n",
    "    max_iters\n",
    "):\n",
    "    input_images = np.array(input_images)\n",
    "    batch_size, orig_h, orig_w, orig_c = input_images.shape\n",
    "    print(\"input images mean {mean} and stddev {stddev}\".format(mean=np.mean(input_images), stddev=np.std(input_images)))\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            targets_var = tf.get_variable(\n",
    "                name=\"targets\",\n",
    "                shape=target_vectors.shape,\n",
    "            )\n",
    "            sess.run(tf.assign(targets_var, target_vectors))\n",
    "            \n",
    "            images_input_ph = tf.placeholder(\n",
    "                tf.float32,\n",
    "                name=\"input_images\",\n",
    "                shape=input_images.shape\n",
    "            )\n",
    "            \n",
    "            noise_var = tf.get_variable(\n",
    "                name=\"adversarial_noise\",\n",
    "                shape=input_images.shape,\n",
    "                initializer=tf.initializers.truncated_normal(\n",
    "                    mean=np.mean(input_images),\n",
    "                    stddev=3 * np.std(input_images)\n",
    "                )\n",
    "            )\n",
    "            sess.run(noise_var.initializer)\n",
    "            \n",
    "            images_plus_noise = images_input_ph + noise_var\n",
    "            randomized_images_plus_noise = images_plus_noise\n",
    "#             randomized_images_plus_noise = tf.image.random_brightness(\n",
    "#                 images_plus_noise, 0.5)\n",
    "#             print(\"shape of inputs\", randomized_images_plus_noise.shape)\n",
    "        \n",
    "#             randomized_images_plus_noise = tf.image.random_crop(\n",
    "#                 randomized_images_plus_noise, \n",
    "#                 [batch_size, orig_h - 10, orig_w - 10, 3]\n",
    "#             )\n",
    "#             print(\"shape of inputs\", randomized_images_plus_noise.shape.as_list())\n",
    "\n",
    "#             randomized_images_plus_noise = tf.image.resize_images(\n",
    "#                 randomized_images_plus_noise, [orig_h, orig_w])\n",
    "#             print(\"shape of inputs\", randomized_images_plus_noise.shape.as_list())\n",
    "            \n",
    "#             randomized_images_plus_noise += tf.random.normal(\n",
    "#                 randomized_images_plus_noise.shape, 0.0, 0.75)\n",
    "#             print(\"shape of inputs\", randomized_images_plus_noise.shape.as_list())\n",
    "            \n",
    "#             randomized_images_plus_noise = tf.clip_by_value(\n",
    "#                 randomized_images_plus_noise, input_images - epsilon, input_images + epsilon)\n",
    "#             print(\"shape of inputs\", randomized_images_plus_noise.shape.as_list())\n",
    "            \n",
    "            model = build_model_fn(\n",
    "                inputs=randomized_images_plus_noise, \n",
    "                sess=sess\n",
    "            )\n",
    "            \n",
    "            model_outputs = tf.nn.l2_normalize(model.net, axis=1)\n",
    "            targets = tf.nn.l2_normalize(targets_var, axis=1)\n",
    "            loss = tf.losses.cosine_distance(targets, model_outputs, axis=1)\n",
    "            print(\"loss shape\", loss.shape)\n",
    "        \n",
    "            total_loss = loss #+ 1e-6 * tf.nn.l2_loss(noise_var)\n",
    "            \n",
    "            vars_before = set(tf.global_variables())\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate).minimize(total_loss, var_list=[noise_var])\n",
    "            vars_after = set(tf.global_variables())\n",
    "            sess.run([v.initializer for v in list(vars_after - vars_before)])\n",
    "            \n",
    "            \n",
    "            losses = []\n",
    "            for i in range(max_iters):\n",
    "                print(\"mean of noise var\", sess.run(tf.reduce_mean(noise_var)))\n",
    "                print(\"mean of input\", \n",
    "                      sess.run(\n",
    "                          tf.reduce_mean(randomized_images_plus_noise), feed_dict={images_input_ph: input_images}))\n",
    "                print(\"loss\", \n",
    "                      sess.run(\n",
    "                          loss, feed_dict={images_input_ph: input_images}))\n",
    "                print(\"targets\", sess.run(targets_var))\n",
    "                print(\"input images mean {mean} and stddev {stddev}\".format(mean=np.mean(input_images), stddev=np.std(input_images)))\n",
    "\n",
    "                loss_value, total_loss_value, _ = sess.run(\n",
    "                    [loss, total_loss, train_op], feed_dict={images_input_ph: input_images})\n",
    "                print(i, loss_value, total_loss_value)\n",
    "                assert not np.isnan(loss_value), \"Loss_value is nan\"\n",
    "                losses.append(loss_value)\n",
    "            \n",
    "            final_imgs = sess.run(\n",
    "                tf.clip_by_value(images_plus_noise, input_images - epsilon, input_images + epsilon),\n",
    "                feed_dict={images_input_ph: input_images}\n",
    "            )\n",
    "            \n",
    "            return final_imgs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_decoys(\n",
    "    people_list,\n",
    "    attack_strategy,\n",
    "    model_to_attack,\n",
    "    learning_rate,\n",
    "    epsilon,\n",
    "    max_iters\n",
    "):\n",
    "    if model_to_attack == \"vggface2\":\n",
    "        model_build_fn = build_vggface_model\n",
    "    elif model_to_attack == \"casia-webface\":\n",
    "        model_build_fn = build_casiawebface_model\n",
    "        \n",
    "    for person in tqdm(people_list):\n",
    "        num, height, width, channels = person.clean_images.shape\n",
    "        person.adversarial_images = np.zeros((2*(len(people_list) - 1), height, width, channels))\n",
    "        indx = 0\n",
    "        for other_person in tqdm(people_list):\n",
    "            if person.person_name == other_person.person_name:\n",
    "                continue\n",
    "            target_vector = np.mean(other_person.clean_embeddings, axis=0)\n",
    "            images_to_make_adversarial = person.clean_images[indx : indx + 2] \n",
    "            targets_for_images = np.array([target_vector for _ in range(len(images_to_make_adversarial))])\n",
    "            person.adversarial_images[indx : indx + 2], losses = attack_batch(\n",
    "                model_build_fn, \n",
    "                images_to_make_adversarial,\n",
    "                targets_for_images,\n",
    "                learning_rate,\n",
    "                epsilon,\n",
    "                max_iters\n",
    "            )\n",
    "            print(\"Done generating decoys by\", person.person_name, \"for\", other_person.person_name)\n",
    "            \n",
    "            fig, ax = fig1, ax1 = plt.subplots()\n",
    "            ax.plot(range(len(losses)), losses)\n",
    "            plt.show()\n",
    "            \n",
    "            save_dest = os.path.join(\n",
    "                \"/data/vggface/test_perturbed_sampled\",\n",
    "                person.person_name,\n",
    "                \"{attack_strategy}_{model}\".format(attack_strategy=attack_strategy, model=model_to_attack),\n",
    "                other_person.person_name\n",
    "            )\n",
    "            \n",
    "            save_path = os.path.join(save_dest, \"epsilon_{}\".format(epsilon), \"png\")\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            existing_files = os.listdir(save_path)\n",
    "\n",
    "            # Clean up folder if need be\n",
    "            if len(existing_files) > 0:\n",
    "                for f in existing_files:\n",
    "                    os.remove(os.path.join(save_path, f))\n",
    "            \n",
    "            for i in range(indx, indx + 2):\n",
    "                orig_name = person.orig_paths[i].split(\"/\")[-1]\n",
    "                \n",
    "                full_save_path = os.path.join(save_path, orig_name)\n",
    "                print(\"Saving to\", save_path)\n",
    "                Image.fromarray(\n",
    "                    person._undo_preprocess(person.adversarial_images[i])\n",
    "                ).save(full_save_path)\n",
    "\n",
    "            indx += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_decoys(\n",
    "#     people,\n",
    "#     \"mean\",\n",
    "#     \"vggface2\",\n",
    "#     0.1,\n",
    "#     0.1,\n",
    "#     100\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_decoys_bigger_batches(\n",
    "    people_list,\n",
    "    attack_strategy,\n",
    "    model_to_attack,\n",
    "    learning_rate,\n",
    "    epsilon,\n",
    "    max_iters\n",
    "):\n",
    "    if model_to_attack == \"vggface2\":\n",
    "        model_build_fn = build_vggface_model\n",
    "    elif model_to_attack == \"casia-webface\":\n",
    "        model_build_fn = build_casiawebface_model\n",
    "        \n",
    "    for person in tqdm(people_list):\n",
    "        num, height, width, channels = person.clean_images.shape\n",
    "        person.adversarial_images = np.zeros((2*(len(people_list) - 1), height, width, channels))\n",
    "        \n",
    "        indx = 0\n",
    "        \n",
    "        images_to_make_adversarial = []\n",
    "        targets_for_images = []\n",
    "        \n",
    "        for other_person in people_list:\n",
    "            if person.person_name == other_person.person_name:\n",
    "                continue\n",
    "                \n",
    "            current_chosen_indices = range(indx, indx + 2)\n",
    "            images_to_make_adversarial.extend(np.take(\n",
    "                person.clean_images, current_chosen_indices, axis=0))\n",
    "            \n",
    "            target_vector = np.mean(other_person.clean_embeddings, axis=0)\n",
    "            targets_for_images.extend(np.array([\n",
    "                target_vector for _ in range(len(current_chosen_indices))]))\n",
    "            \n",
    "            indx += 2\n",
    "            \n",
    "        images_to_make_adversarial = np.array(images_to_make_adversarial)\n",
    "        \n",
    "        all_adversarial_images, losses = attack_batch_cw(\n",
    "            model_build_fn, \n",
    "            np.array(images_to_make_adversarial),\n",
    "            np.array(targets_for_images),\n",
    "            learning_rate,\n",
    "            epsilon,\n",
    "            max_iters\n",
    "        )\n",
    "            \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(range(len(losses)), losses)\n",
    "        plt.show()\n",
    "        \n",
    "        indx = 0\n",
    "        for other_person in people_list:\n",
    "            if person.person_name == other_person.person_name:\n",
    "                continue\n",
    "            \n",
    "            save_dest = os.path.join(\n",
    "                \"/data/vggface/test_perturbed_sampled\",\n",
    "                person.person_name,\n",
    "                \"{attack_strategy}_{model}\".format(attack_strategy=attack_strategy, model=model_to_attack),\n",
    "                other_person.person_name\n",
    "            )\n",
    "            \n",
    "            save_path = os.path.join(save_dest, \"epsilon_{}\".format(epsilon), \"png\")\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            existing_files = os.listdir(save_path)\n",
    "\n",
    "            # Clean up folder if need be\n",
    "            if len(existing_files) > 0:\n",
    "                for f in existing_files:\n",
    "                    os.remove(os.path.join(save_path, f))\n",
    "            \n",
    "            for i in range(indx, indx + 2):\n",
    "                orig_name = person.orig_paths[i].split(\"/\")[-1]\n",
    "                person.adversarial_images[i] = all_adversarial_images[i]\n",
    "                full_save_path = os.path.join(save_path, orig_name)\n",
    "                print(\"Saving to\", save_path)\n",
    "                Image.fromarray(\n",
    "                    person._undo_preprocess(person.adversarial_images[i])\n",
    "                ).save(full_save_path)\n",
    "\n",
    "            indx += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from /home/ivan/facenet/models/20180402-114759/model-20180402-114759.ckpt-275\n",
      "loss shape ()\n",
      "mean of noise var 0.0012735219\n",
      "mean of input 0.0012735314\n",
      "loss 1.0091147\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "0 1.0091147 1.0091147\n",
      "mean of noise var 0.0016066105\n",
      "mean of input 0.0016066219\n",
      "loss 0.7661517\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "1 0.7661517 0.7661517\n",
      "mean of noise var 0.0019425567\n",
      "mean of input 0.0019425639\n",
      "loss 0.60378546\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "2 0.60378546 0.60378546\n",
      "mean of noise var 0.0022215247\n",
      "mean of input 0.002221535\n",
      "loss 0.5079535\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "3 0.5079535 0.5079535\n",
      "mean of noise var 0.0024613552\n",
      "mean of input 0.0024613636\n",
      "loss 0.43857408\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "4 0.43857405 0.43857405\n",
      "mean of noise var 0.0027272743\n",
      "mean of input 0.0027272792\n",
      "loss 0.38145962\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "5 0.38145962 0.38145962\n",
      "mean of noise var 0.0029606107\n",
      "mean of input 0.0029606165\n",
      "loss 0.33923158\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "6 0.33923158 0.33923158\n",
      "mean of noise var 0.0031726463\n",
      "mean of input 0.0031726554\n",
      "loss 0.30707923\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "7 0.30707923 0.30707923\n",
      "mean of noise var 0.0033677784\n",
      "mean of input 0.003367784\n",
      "loss 0.27849257\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "8 0.27849257 0.27849257\n",
      "mean of noise var 0.0035134358\n",
      "mean of input 0.003513442\n",
      "loss 0.25290206\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "9 0.25290206 0.25290206\n",
      "mean of noise var 0.0036352363\n",
      "mean of input 0.0036352465\n",
      "loss 0.22821623\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "10 0.22821623 0.22821623\n",
      "mean of noise var 0.0037363614\n",
      "mean of input 0.0037363684\n",
      "loss 0.20634992\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "11 0.20634992 0.20634992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of noise var 0.0038041016\n",
      "mean of input 0.0038041077\n",
      "loss 0.18682724\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "12 0.18682724 0.18682724\n",
      "mean of noise var 0.0038546855\n",
      "mean of input 0.003854694\n",
      "loss 0.17092633\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "13 0.17092632 0.17092632\n",
      "mean of noise var 0.0038828645\n",
      "mean of input 0.0038828729\n",
      "loss 0.15377705\n",
      "targets [[ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 0.25508723  0.3961168   1.215363   ... -0.37649658 -1.2318215\n",
      "   0.46316475]\n",
      " [ 2.0642266   0.40784636 -0.9280291  ... -0.40743008  0.05588722\n",
      "  -1.1745586 ]\n",
      " ...\n",
      " [ 1.2804402   0.8868904  -1.2757783  ... -0.665468    0.2846522\n",
      "  -0.74040914]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]\n",
      " [ 0.6271096   0.517079    0.23785053 ...  0.02542643 -0.18105283\n",
      "  -0.497792  ]]\n",
      "input images mean 9.97825910786787e-09 and stddev 1.0000001192092896\n",
      "14 0.15377705 0.15377705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4f663e9be422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-17-252e4b9e34d2>\u001b[0m in \u001b[0;36mgenerate_decoys_bigger_batches\u001b[0;34m(people_list, attack_strategy, model_to_attack, learning_rate, epsilon, max_iters)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mmax_iters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         )\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5e29da1915ef>\u001b[0m in \u001b[0;36mattack_batch_cw\u001b[0;34m(build_model_fn, input_images, target_vectors, learning_rate, epsilon, max_iters)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean of noise var\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 print(\"mean of input\", \n\u001b[1;32m     82\u001b[0m                       sess.run(\n",
      "\u001b[0;32m/home/ivan/anaconda3/envs/facenet-gpu-112/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ivan/anaconda3/envs/facenet-gpu-112/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ivan/anaconda3/envs/facenet-gpu-112/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ivan/anaconda3/envs/facenet-gpu-112/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ivan/anaconda3/envs/facenet-gpu-112/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m/home/ivan/anaconda3/envs/facenet-gpu-112/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_decoys_bigger_batches(\n",
    "    people,\n",
    "    \"mean\",\n",
    "    \"vggface2\",\n",
    "    0.1,\n",
    "    0.1,\n",
    "    100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    a = [[1., 2., 3.], [4., 5., 6.]]\n",
    "    b = [[7., 8., 9.], [10., 11., 12.]]\n",
    "    print(\"tensorflow computed\", \n",
    "          sess.run(tf.losses.cosine_distance(\n",
    "              tf.nn.l2_normalize(a, axis=1), \n",
    "              tf.nn.l2_normalize(b, axis=1), \n",
    "              axis=1)))\n",
    "    print(\"shape of normalize a\", tf.nn.l2_normalize(a, axis=0).shape.as_list())\n",
    "    print(\"shape of normalize b\", tf.nn.l2_normalize(b, axis=0).shape.as_list())\n",
    "    print(\"shape of multiply\", tf.multiply(\n",
    "                  tf.nn.l2_normalize(a, axis=0), \n",
    "                  tf.nn.l2_normalize(b, axis=0)).shape.as_list())\n",
    "    mult = tf.multiply(\n",
    "                  tf.nn.l2_normalize(a, axis=1), \n",
    "                  tf.nn.l2_normalize(b, axis=1))\n",
    "    print(\"mutiplied\", sess.run(mult))\n",
    "    print(\n",
    "        \"custom tensorflow\",\n",
    "        sess.run(1.0 - tf.reduce_sum(mult, axis=1)))\n",
    "\n",
    "\n",
    "pd = pairwise_distances(a, b, metric=\"cosine\")\n",
    "print(pd)\n",
    "print(pd[0, 0] + pd[1, 1])\n",
    "print((pd[0, 0] + pd[1, 1])/2.0)\n",
    "for a_i, b_i in zip(a, b):\n",
    "    multiplied = (a_i/np.linalg.norm(a_i, ord=2)) * (b_i/np.linalg.norm(b_i, ord=2))\n",
    "    print(\"multiplied\", multiplied)\n",
    "    print(1.0 - np.sum(multiplied))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
